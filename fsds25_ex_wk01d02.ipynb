{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feba84ac",
   "metadata": {},
   "source": [
    "# Fundamentals of Social Data Science 2025. Week 1. Day 2. Exercises\n",
    "\n",
    "This is a group assignment. \n",
    "\n",
    "You will be expected to submit an individual assignment on Tuesday at 12pm (not Monday) on Canvas. The sheet that you will be expected to submit will be released on Friday at 12pm. It is submitted on Tuesday because you will want to integrate your materials post-presentation. \n",
    "\n",
    "- That sheet will have a small number of individual questions related to Friday's assignment\n",
    "- It will include one question about your presentation. That question is reproduced below so there are no surprises. \n",
    "\n",
    "The assignment submission details will be posted on Canvas under assignments.\n",
    "\n",
    "To itemise: \n",
    "- Week 1. Day 2. Wednesday at 12pm: This \"getting started\" sheet is released. \n",
    "- Wednesday afternoon tutorial: We will want to ensure that you can get started on loading data. \n",
    "- Week 1. Day 3. Friday at 12pm: The individual assignment is released. \n",
    "- Week 1. Day 3. Friday afternoon tutorial: You will want to play with the Claude artifact as well as continue working with your group. \n",
    "- Week 2. Day 1. Monday at 12pm: An exercise will be released related to Network Canvas. It will require you to download Network Canvas interviewer from networkcanvas.com. \n",
    "- Week 2. Day 1. Monday afternoon tutorial: Bernie will explain the Network Canvas exercise as a part of the class. The tutorial period will be group presentations. \n",
    "- Tuesday at 12pm: Your individual assignment is due. \n",
    "- Tuesday at 12pm: Your group assignment should be posted. \n",
    "\n",
    "> **NOTE:** This assignment will use data from the web. This assignment has NOT been cleared for research via the CUREC process. It is an in-class assignment. Therefore, if you wish to publish anything from this analysis, you must first apply for a CUREC before publishing anything publicly with your Oxford affiliation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404f3cb",
   "metadata": {},
   "source": [
    "# Group exercise: Getting started\n",
    "\n",
    "The group assignment will make use of the StackDownloader from the FSSTDS repository. This downloader (recently tested) will download, extract and process a StackExchange archive. It is pretty close to 'one click'. It creates a 'feather' archive, which is a very nice format for compressing DataFrames. You can open this in your own code. \n",
    "\n",
    "To begin, you will need to have everything installed for the StackDownloader. How do we do that? We install the requirements.\n",
    "\n",
    "- **Step 1.** Clone the FSSTDS repository. \n",
    "- **Step 2.** Open the Ch.00.Stack_downloader and 'select kernel', select \"Python Environments...\", \"Create Python Environment\", \"Venv -> Creates a `.venv` virtual environment in the current workspace\", select **Python 3.12**. Note 3.14 is untested. Select dependencies to install -> requirements.txt. \n",
    "- **Step 3.** Run the big code cell in Stack_downloader. Select a specific archive. \n",
    "- **Step 4.** Locate and load the DataFrame. You can now use the Stack Exchange in your work. \n",
    "\n",
    "Note if you get errors with PyArrow below, try restarting the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4ac8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/calebagoha/Desktop/fundamentals_of_sds/.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: pyarrow in /Users/calebagoha/Desktop/fundamentals_of_sds/.venv/lib/python3.12/site-packages (21.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/calebagoha/Desktop/fundamentals_of_sds/.venv/lib/python3.12/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/calebagoha/Desktop/fundamentals_of_sds/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/calebagoha/Desktop/fundamentals_of_sds/.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/calebagoha/Desktop/fundamentals_of_sds/.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/calebagoha/Desktop/fundamentals_of_sds/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In case this Jupyter Notebook is in a different repo than FSSTDS, you may need to install\n",
    "# pandas and pyarrow to parse the file. \n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pandas\", \"pyarrow\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7c44f",
   "metadata": {},
   "source": [
    "## Q2. Defining helpfulness \n",
    "\n",
    "If you can describe the data simply then you are on your way to the big question for the group. Recall two of the trade-offs from the last lecture: \"operationalisation\" and \"coding\". The group project this week is very simple in some senses and very complex in other senses: \n",
    "\n",
    "Two questions: \n",
    "> - \"How can we identify the most helpful users in this space\" \n",
    "> - \"When were the helpful users the most helpful or most active?\"\n",
    "\n",
    "So this means that your group will have to discuss:\n",
    "- What defines helpfulness? Are there multiple possible metrics? \n",
    "- Do we think that a helpful person should _always_ be helpful? \n",
    "- Is helpfulness topic-specific? \n",
    "- You may want to explore wrangling the data by time. \n",
    "\n",
    "We do not expect you to merge in data from the users.xml / users.feather for this. However, you may want to explore how to create a datatime column. This is not covered in this lecture, but you may want to read either Chapter 10 of FSSTDS on cleaning data and Chapter 12 of FSSTDS on wrangling time data. \n",
    "\n",
    "You will want to divide some tasks among your group. Some might be delegated to surf the space online to come up with abductive hypotheses. Some might want to focus on rendering some charts. Some might be excellent at presentation design or at presenting to the group. Lean into your expertise and collaborate.\n",
    "\n",
    "Presentations for this will be on Monday afternoon. The presentations will be no more than 12 minutes + 3 minutes of questions & transition. \n",
    "\n",
    "Each group will have a 'space' on Canvas to submit 3 things: \n",
    "- the presentation \n",
    "- the code\n",
    "- the 'credits'. A single sheet (in docx/md) that details which group members participated in which ways. Treat this not merely as accountability but an opportunity to signal your own strengths. We do not expect everyone to do 1/5 of the work for every task. We do expect everyone to contribute in some way.\n",
    "\n",
    "This code will not be graded but it will be made available to other students. \n",
    "The presentations will be given short written feedback by the instructor post-presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67000fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2409 entries, 0 to 2408\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   Id                     2409 non-null   object        \n",
      " 1   PostTypeId             2409 non-null   object        \n",
      " 2   AcceptedAnswerId       381 non-null    object        \n",
      " 3   CreationDate           2409 non-null   datetime64[ns]\n",
      " 4   Score                  2409 non-null   int64         \n",
      " 5   ViewCount              760 non-null    float64       \n",
      " 6   Body                   2409 non-null   object        \n",
      " 7   OwnerUserId            2345 non-null   object        \n",
      " 8   LastEditorUserId       1418 non-null   object        \n",
      " 9   LastEditDate           1438 non-null   datetime64[ns]\n",
      " 10  LastActivityDate       2409 non-null   datetime64[ns]\n",
      " 11  Title                  760 non-null    object        \n",
      " 12  Tags                   760 non-null    object        \n",
      " 13  AnswerCount            760 non-null    float64       \n",
      " 14  CommentCount           2409 non-null   int64         \n",
      " 15  ContentLicense         2409 non-null   object        \n",
      " 16  ClosedDate             64 non-null     datetime64[ns]\n",
      " 17  ParentId               1497 non-null   object        \n",
      " 18  FavoriteCount          7 non-null      float64       \n",
      " 19  OwnerDisplayName       68 non-null     object        \n",
      " 20  LastEditorDisplayName  22 non-null     object        \n",
      " 21  CommunityOwnedDate     14 non-null     datetime64[ns]\n",
      " 22  BodyText               2409 non-null   object        \n",
      " 23  BodyURLs               2409 non-null   object        \n",
      " 24  TagsList               2409 non-null   object        \n",
      "dtypes: datetime64[ns](5), float64(3), int64(2), object(15)\n",
      "memory usage: 470.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Q0. Check that you can load your own DataFrame\n",
    " \n",
    "import pandas as pd \n",
    "\n",
    "stack_df = df = pd.read_feather(\"/Users/calebagoha/Desktop/fundamentals_of_sds/group4_fsstds/data/vegetarianism.stackexchange.com/Posts.feather\")\n",
    "\n",
    "print(stack_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde27f51",
   "metadata": {},
   "source": [
    "### Load all data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c83143",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_xml(\"/Users/calebagoha/Desktop/fundamentals_of_sds/group4_fsstds/data/vegetarianism.stackexchange.com/Users.xml\", xpath=\".//row\")\n",
    "votes = pd.read_xml(\"/Users/calebagoha/Desktop/fundamentals_of_sds/group4_fsstds/data/vegetarianism.stackexchange.com/Votes.xml\", xpath=\".//row\")\n",
    "comments = pd.read_xml(\"/Users/calebagoha/Desktop/fundamentals_of_sds/group4_fsstds/data/vegetarianism.stackexchange.com/Comments.xml\", xpath=\".//row\")\n",
    "badges = pd.read_xml(\"/Users/calebagoha/Desktop/fundamentals_of_sds/group4_fsstds/data/vegetarianism.stackexchange.com/Badges.xml\", xpath=\".//row\")\n",
    "post_links = pd.read_xml(\"/Users/calebagoha/Desktop/fundamentals_of_sds/group4_fsstds/data/vegetarianism.stackexchange.com/PostLinks.xml\", xpath=\".//row\")\n",
    "post_history = pd.read_xml(\"/Users/calebagoha/Desktop/fundamentals_of_sds/group4_fsstds/data/vegetarianism.stackexchange.com/PostHistory.xml\", xpath=\".//row\")\n",
    "posts = pd.read_xml(\"/Users/calebagoha/Desktop/fundamentals_of_sds/group4_fsstds/data/vegetarianism.stackexchange.com/Posts.xml\", xpath=\".//row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b5b6bb",
   "metadata": {},
   "source": [
    "### Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fe55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = posts[posts[\"PostTypeId\"] == 2].copy()\n",
    "answers[\"OwnerUserId\"] = answers[\"OwnerUserId\"].fillna(-999) # replace missings with invalid id (might be deleted accounts) there are 38 of them\n",
    "\n",
    "users['CreationDate'] = pd.to_datetime(users['CreationDate'], errors='coerce')\n",
    "users['LastAccessDate'] = pd.to_datetime(users['LastAccessDate'], errors='coerce')\n",
    "\n",
    "badges = badges[[\"UserId\", \"Name\"]]\n",
    "badges_by_user = badges.groupby('UserId', dropna=False)['Name'].agg(list).reset_index().rename(columns={'Name': 'badges'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98047b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute per question total answer score\n",
    "totals = answers.groupby('ParentId', dropna=False)['Score'].sum().rename('TotalAnswerScore').reset_index()\n",
    "\n",
    "# merge question totals back onto answers\n",
    "answers = answers.merge(totals, on=\"ParentId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db570128",
   "metadata": {},
   "source": [
    "- Posts was filtered to only contain answers.\n",
    "- New column created to keep total answer score per post\n",
    "- Next Steps: Kiki creates new column for normalized score\n",
    "- Next Steps: Howard groups by userId to get aggregate normalized score and total post volume\n",
    "- Next Steps: Caleb finishes creating centralized dataset by including badges, and other descriptive data on the user level for Michi and Çelikhan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a13d03",
   "metadata": {},
   "source": [
    "### Creating Centralized Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
