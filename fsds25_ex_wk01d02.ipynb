{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feba84ac",
   "metadata": {},
   "source": [
    "# Fundamentals of Social Data Science 2025. Week 1. Day 2. Exercises\n",
    "\n",
    "This is a group assignment. \n",
    "\n",
    "You will be expected to submit an individual assignment on Tuesday at 12pm (not Monday) on Canvas. The sheet that you will be expected to submit will be released on Friday at 12pm. It is submitted on Tuesday because you will want to integrate your materials post-presentation. \n",
    "\n",
    "- That sheet will have a small number of individual questions related to Friday's assignment\n",
    "- It will include one question about your presentation. That question is reproduced below so there are no surprises. \n",
    "\n",
    "The assignment submission details will be posted on Canvas under assignments.\n",
    "\n",
    "To itemise: \n",
    "- Week 1. Day 2. Wednesday at 12pm: This \"getting started\" sheet is released. \n",
    "- Wednesday afternoon tutorial: We will want to ensure that you can get started on loading data. \n",
    "- Week 1. Day 3. Friday at 12pm: The individual assignment is released. \n",
    "- Week 1. Day 3. Friday afternoon tutorial: You will want to play with the Claude artifact as well as continue working with your group. \n",
    "- Week 2. Day 1. Monday at 12pm: An exercise will be released related to Network Canvas. It will require you to download Network Canvas interviewer from networkcanvas.com. \n",
    "- Week 2. Day 1. Monday afternoon tutorial: Bernie will explain the Network Canvas exercise as a part of the class. The tutorial period will be group presentations. \n",
    "- Tuesday at 12pm: Your individual assignment is due. \n",
    "- Tuesday at 12pm: Your group assignment should be posted. \n",
    "\n",
    "> **NOTE:** This assignment will use data from the web. This assignment has NOT been cleared for research via the CUREC process. It is an in-class assignment. Therefore, if you wish to publish anything from this analysis, you must first apply for a CUREC before publishing anything publicly with your Oxford affiliation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404f3cb",
   "metadata": {},
   "source": [
    "# Group exercise: Getting started\n",
    "\n",
    "The group assignment will make use of the StackDownloader from the FSSTDS repository. This downloader (recently tested) will download, extract and process a StackExchange archive. It is pretty close to 'one click'. It creates a 'feather' archive, which is a very nice format for compressing DataFrames. You can open this in your own code. \n",
    "\n",
    "To begin, you will need to have everything installed for the StackDownloader. How do we do that? We install the requirements.\n",
    "\n",
    "- **Step 1.** Clone the FSSTDS repository. \n",
    "- **Step 2.** Open the Ch.00.Stack_downloader and 'select kernel', select \"Python Environments...\", \"Create Python Environment\", \"Venv -> Creates a `.venv` virtual environment in the current workspace\", select **Python 3.12**. Note 3.14 is untested. Select dependencies to install -> requirements.txt. \n",
    "- **Step 3.** Run the big code cell in Stack_downloader. Select a specific archive. \n",
    "- **Step 4.** Locate and load the DataFrame. You can now use the Stack Exchange in your work. \n",
    "\n",
    "Note if you get errors with PyArrow below, try restarting the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a4ac8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas in /Users/xiongjiaqi/miniconda3/envs/fsstds/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: pyarrow in /Users/xiongjiaqi/miniconda3/envs/fsstds/lib/python3.12/site-packages (21.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/xiongjiaqi/miniconda3/envs/fsstds/lib/python3.12/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/xiongjiaqi/miniconda3/envs/fsstds/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/xiongjiaqi/miniconda3/envs/fsstds/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/xiongjiaqi/miniconda3/envs/fsstds/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/xiongjiaqi/miniconda3/envs/fsstds/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In case this Jupyter Notebook is in a different repo than FSSTDS, you may need to install\n",
    "# pandas and pyarrow to parse the file. \n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pandas\", \"pyarrow\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7c44f",
   "metadata": {},
   "source": [
    "## Q2. Defining helpfulness \n",
    "\n",
    "If you can describe the data simply then you are on your way to the big question for the group. Recall two of the trade-offs from the last lecture: \"operationalisation\" and \"coding\". The group project this week is very simple in some senses and very complex in other senses: \n",
    "\n",
    "Two questions: \n",
    "> - \"How can we identify the most helpful users in this space\" \n",
    "> - \"When were the helpful users the most helpful or most active?\"\n",
    "\n",
    "So this means that your group will have to discuss:\n",
    "- What defines helpfulness? Are there multiple possible metrics? \n",
    "- Do we think that a helpful person should _always_ be helpful? \n",
    "- Is helpfulness topic-specific? \n",
    "- You may want to explore wrangling the data by time. \n",
    "\n",
    "We do not expect you to merge in data from the users.xml / users.feather for this. However, you may want to explore how to create a datatime column. This is not covered in this lecture, but you may want to read either Chapter 10 of FSSTDS on cleaning data and Chapter 12 of FSSTDS on wrangling time data. \n",
    "\n",
    "You will want to divide some tasks among your group. Some might be delegated to surf the space online to come up with abductive hypotheses. Some might want to focus on rendering some charts. Some might be excellent at presentation design or at presenting to the group. Lean into your expertise and collaborate.\n",
    "\n",
    "Presentations for this will be on Monday afternoon. The presentations will be no more than 12 minutes + 3 minutes of questions & transition. \n",
    "\n",
    "Each group will have a 'space' on Canvas to submit 3 things: \n",
    "- the presentation \n",
    "- the code\n",
    "- the 'credits'. A single sheet (in docx/md) that details which group members participated in which ways. Treat this not merely as accountability but an opportunity to signal your own strengths. We do not expect everyone to do 1/5 of the work for every task. We do expect everyone to contribute in some way.\n",
    "\n",
    "This code will not be graded but it will be made available to other students. \n",
    "The presentations will be given short written feedback by the instructor post-presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67000fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b36bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2409 entries, 0 to 2408\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   Id                     2409 non-null   object        \n",
      " 1   PostTypeId             2409 non-null   object        \n",
      " 2   AcceptedAnswerId       381 non-null    object        \n",
      " 3   CreationDate           2409 non-null   datetime64[ns]\n",
      " 4   Score                  2409 non-null   int64         \n",
      " 5   ViewCount              760 non-null    float64       \n",
      " 6   Body                   2409 non-null   object        \n",
      " 7   OwnerUserId            2345 non-null   object        \n",
      " 8   LastEditorUserId       1418 non-null   object        \n",
      " 9   LastEditDate           1438 non-null   datetime64[ns]\n",
      " 10  LastActivityDate       2409 non-null   datetime64[ns]\n",
      " 11  Title                  760 non-null    object        \n",
      " 12  Tags                   760 non-null    object        \n",
      " 13  AnswerCount            760 non-null    float64       \n",
      " 14  CommentCount           2409 non-null   int64         \n",
      " 15  ContentLicense         2409 non-null   object        \n",
      " 16  ClosedDate             64 non-null     datetime64[ns]\n",
      " 17  ParentId               1497 non-null   object        \n",
      " 18  FavoriteCount          7 non-null      float64       \n",
      " 19  OwnerDisplayName       68 non-null     object        \n",
      " 20  LastEditorDisplayName  22 non-null     object        \n",
      " 21  CommunityOwnedDate     14 non-null     datetime64[ns]\n",
      " 22  BodyText               2409 non-null   object        \n",
      " 23  BodyURLs               2409 non-null   object        \n",
      " 24  TagsList               2409 non-null   object        \n",
      "dtypes: datetime64[ns](5), float64(3), int64(2), object(15)\n",
      "memory usage: 470.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Q0. Check that you can load your own DataFrame\n",
    " \n",
    "import pandas as pd \n",
    "\n",
    "stack_df = df = pd.read_feather(\"./data/vegetarianism.stackexchange.com/Posts.feather\")\n",
    "\n",
    "print(stack_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde27f51",
   "metadata": {},
   "source": [
    "### Load all data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90c83143",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_xml(\"data/vegetarianism.stackexchange.com/Users.xml\", xpath=\".//row\")\n",
    "votes = pd.read_xml(\"data/vegetarianism.stackexchange.com/Votes.xml\", xpath=\".//row\")\n",
    "comments = pd.read_xml(\"data/vegetarianism.stackexchange.com/Comments.xml\", xpath=\".//row\")\n",
    "badges = pd.read_xml(\"data/vegetarianism.stackexchange.com/Badges.xml\", xpath=\".//row\")\n",
    "post_links = pd.read_xml(\"data/vegetarianism.stackexchange.com/PostLinks.xml\", xpath=\".//row\")\n",
    "post_history = pd.read_xml(\"data/vegetarianism.stackexchange.com/PostHistory.xml\", xpath=\".//row\")\n",
    "posts = pd.read_xml(\"data/vegetarianism.stackexchange.com/Posts.xml\", xpath=\".//row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b5b6bb",
   "metadata": {},
   "source": [
    "### Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180fe55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = posts[posts[\"PostTypeId\"] == 2].copy()\n",
    "answers[\"OwnerUserId\"] = answers[\"OwnerUserId\"].fillna(-999) # replace missings with invalid id (might be deleted accounts) there are 38 of them\n",
    "\n",
    "answers['Score'] = answers['Score'].clip(lower=0)# Assign the negative scores to 0\n",
    "\n",
    "users['CreationDate'] = pd.to_datetime(users['CreationDate'], errors='coerce')\n",
    "users['LastAccessDate'] = pd.to_datetime(users['LastAccessDate'], errors='coerce')\n",
    "\n",
    "badges = badges[[\"UserId\", \"Name\"]]\n",
    "badges_by_user = badges.groupby('UserId', dropna=False)['Name'].agg(list).reset_index().rename(columns={'Name': 'badges'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98047b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute per question total answer score\n",
    "totals = answers.groupby('ParentId', dropna=False)['Score'].sum().rename('TotalAnswerScore').reset_index()\n",
    "\n",
    "# merge question totals back onto answers\n",
    "answers = answers.merge(totals, on=\"ParentId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e97f2",
   "metadata": {},
   "source": [
    "## Calculate the Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85ed866b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized score distribution:\n",
      "count    1497.000000\n",
      "mean        0.466266\n",
      "std         0.373809\n",
      "min         0.000000\n",
      "25%         0.125000\n",
      "50%         0.375000\n",
      "75%         0.969697\n",
      "max         1.000000\n",
      "Name: NormalizedScore, dtype: float64\n",
      "\n",
      "Range: 0.000 to 1.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate normalized score\n",
    "# For questions where TotalAnswerScore > 0: normalized = Score / TotalAnswerScore  \n",
    "# For questions where TotalAnswerScore <= 0: we'll use the raw score (or set to 0)\n",
    "answers['NormalizedScore'] = np.where(\n",
    "    answers['TotalAnswerScore'] > 0,\n",
    "    answers['Score'] / answers['TotalAnswerScore'],\n",
    "    0  # Set to 0 for edge cases\n",
    ")\n",
    "\n",
    "print(\"\\nNormalized score distribution:\")\n",
    "print(answers['NormalizedScore'].describe())\n",
    "print(f\"\\nRange: {answers['NormalizedScore'].min():.3f} to {answers['NormalizedScore'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a213b9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid answers (with known users): 1459\n",
      "\n",
      "Total users analyzed: 406\n",
      "Users with at least 2 answers: 182\n",
      "Users with at least 5 answers: 62\n",
      "\n",
      "User metrics distribution:\n",
      "       AvgNormalizedScore  TotalAnswers  AvgRawScore\n",
      "count          406.000000    406.000000   406.000000\n",
      "mean             0.378978      3.593596     3.412230\n",
      "std              0.319368      8.695954     3.137362\n",
      "min              0.000000      1.000000     0.000000\n",
      "25%              0.105700      1.000000     1.000000\n",
      "50%              0.319450      1.000000     3.000000\n",
      "75%              0.567650      3.000000     5.000000\n",
      "max              1.000000    118.000000    21.750000\n"
     ]
    }
   ],
   "source": [
    "# Filter out invalid users (those with OwnerUserId == -999)\n",
    "valid_answers = answers[answers['OwnerUserId'] != -999].copy()\n",
    "print(f\"Valid answers (with known users): {len(valid_answers)}\")\n",
    "\n",
    "# Calculate user-level aggregations\n",
    "user_metrics = valid_answers.groupby('OwnerUserId').agg({\n",
    "    'NormalizedScore': ['mean', 'sum', 'count'],\n",
    "    'Score': ['mean', 'sum'],\n",
    "    'Id': 'count'  # Total number of answers per user\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "user_metrics.columns = [\n",
    "    'AvgNormalizedScore', 'TotalNormalizedScore', 'AnswerCount_norm',\n",
    "    'AvgRawScore', 'TotalRawScore', 'TotalAnswers'\n",
    "]\n",
    "\n",
    "# Reset index to make OwnerUserId a column\n",
    "user_metrics = user_metrics.reset_index()\n",
    "\n",
    "print(f\"\\nTotal users analyzed: {len(user_metrics)}\")\n",
    "print(f\"Users with at least 2 answers: {len(user_metrics[user_metrics['TotalAnswers'] >= 2])}\")\n",
    "print(f\"Users with at least 5 answers: {len(user_metrics[user_metrics['TotalAnswers'] >= 5])}\")\n",
    "\n",
    "print(\"\\nUser metrics distribution:\")\n",
    "print(user_metrics[['AvgNormalizedScore', 'TotalAnswers', 'AvgRawScore']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5efe4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TOP 10 USERS BY AVERAGE NORMALIZED SCORE:\n",
      "======================================================================\n",
      "# 1. User 87.0: Avg=1.000 (Answers: 1, Avg Raw Score: 8.0)\n",
      "# 2. User 90.0: Avg=1.000 (Answers: 1, Avg Raw Score: 3.0)\n",
      "# 3. User 186.0: Avg=1.000 (Answers: 1, Avg Raw Score: 4.0)\n",
      "# 4. User 190.0: Avg=1.000 (Answers: 1, Avg Raw Score: 5.0)\n",
      "# 5. User 220.0: Avg=1.000 (Answers: 1, Avg Raw Score: 2.0)\n",
      "# 6. User 232.0: Avg=1.000 (Answers: 1, Avg Raw Score: 5.0)\n",
      "# 7. User 317.0: Avg=1.000 (Answers: 1, Avg Raw Score: 5.0)\n",
      "# 8. User 335.0: Avg=1.000 (Answers: 1, Avg Raw Score: 2.0)\n",
      "# 9. User 355.0: Avg=1.000 (Answers: 1, Avg Raw Score: 2.0)\n",
      "#10. User 384.0: Avg=1.000 (Answers: 1, Avg Raw Score: 4.0)\n",
      "TOP 10 USERS BY TOTAL NORMALIZED CONTRIBUTION:\n",
      "======================================================================\n",
      "# 1. User 74.0: Total=72.291 (Answers: 118, Avg: 0.613)\n",
      "# 2. User 1236.0: Total=59.797 (Answers: 90, Avg: 0.664)\n",
      "# 3. User 164.0: Total=28.074 (Answers: 47, Avg: 0.597)\n",
      "# 4. User 36.0: Total=25.223 (Answers: 43, Avg: 0.587)\n",
      "# 5. User 97.0: Total=16.413 (Answers: 29, Avg: 0.566)\n",
      "# 6. User 3311.0: Total=11.721 (Answers: 16, Avg: 0.733)\n",
      "# 7. User 4031.0: Total=11.687 (Answers: 30, Avg: 0.390)\n",
      "# 8. User 115.0: Total=11.499 (Answers: 21, Avg: 0.548)\n",
      "# 9. User 207.0: Total=11.094 (Answers: 15, Avg: 0.740)\n",
      "#10. User 6.0: Total=10.186 (Answers: 14, Avg: 0.728)\n"
     ]
    }
   ],
   "source": [
    "# Sort by average normalized score (descending)\n",
    "top_users_by_avg = user_metrics.nlargest(10, 'AvgNormalizedScore')\n",
    "\n",
    "print(\" TOP 10 USERS BY AVERAGE NORMALIZED SCORE:\")\n",
    "print(\"=\" * 70)\n",
    "for idx, row in top_users_by_avg.iterrows():\n",
    "    print(f\"#{top_users_by_avg.index.get_loc(idx)+1:2d}. User {row['OwnerUserId']}: \"\n",
    "          f\"Avg={row['AvgNormalizedScore']:.3f} \"\n",
    "          f\"(Answers: {int(row['TotalAnswers'])}, \"\n",
    "          f\"Avg Raw Score: {row['AvgRawScore']:.1f})\")\n",
    "\n",
    "# Also show top users by total contribution\n",
    "top_users_by_total = user_metrics.nlargest(10, 'TotalNormalizedScore')\n",
    "print(\"TOP 10 USERS BY TOTAL NORMALIZED CONTRIBUTION:\")\n",
    "print(\"=\" * 70)\n",
    "for idx, row in top_users_by_total.iterrows():\n",
    "    print(f\"#{top_users_by_total.index.get_loc(idx)+1:2d}. User {row['OwnerUserId']}: \"\n",
    "          f\"Total={row['TotalNormalizedScore']:.3f} \"\n",
    "          f\"(Answers: {int(row['TotalAnswers'])}, \"\n",
    "          f\"Avg: {row['AvgNormalizedScore']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "950422e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/0dzzyfsd4078wfgbndq284380000gn/T/ipykernel_35486/1183251063.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  normalized_score = answers.groupby('OwnerUserId', dropna=True).apply(lambda x: (x['Score'] / x['TotalAnswerScore']).sum()).rename('NormalizedScore').reset_index()\n"
     ]
    }
   ],
   "source": [
    "### Normalized Score\n",
    "normalized_score = answers.groupby('OwnerUserId', dropna=True).apply(lambda x: (x['Score'] / x['TotalAnswerScore']).sum()).rename('NormalizedScore').reset_index()\n",
    "\n",
    "\n",
    "### Total Answer Volume\n",
    "answer_volume = answers.groupby('OwnerUserId', dropna=True).size().rename('TotalAnswerVolume').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8d40106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataframe shape: (406, 13)\n",
      "Master df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 406 entries, 6.0 to 6784.0\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   AvgNormalizedScore    406 non-null    float64       \n",
      " 1   TotalNormalizedScore  406 non-null    float64       \n",
      " 2   AvgRawScore           406 non-null    float64       \n",
      " 3   TotalRawScore         406 non-null    int64         \n",
      " 4   TotalAnswers          406 non-null    int64         \n",
      " 5   badges                387 non-null    object        \n",
      " 6   DisplayName           406 non-null    object        \n",
      " 7   Reputation            406 non-null    int64         \n",
      " 8   CreationDate          406 non-null    datetime64[ns]\n",
      " 9   LastAccessDate        406 non-null    datetime64[ns]\n",
      " 10  Views                 406 non-null    int64         \n",
      " 11  UpVotes               406 non-null    int64         \n",
      " 12  DownVotes             406 non-null    int64         \n",
      "dtypes: datetime64[ns](2), float64(3), int64(6), object(2)\n",
      "memory usage: 44.4+ KB\n",
      "None\n",
      "Master df head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgNormalizedScore</th>\n",
       "      <th>TotalNormalizedScore</th>\n",
       "      <th>AvgRawScore</th>\n",
       "      <th>TotalRawScore</th>\n",
       "      <th>TotalAnswers</th>\n",
       "      <th>badges</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>LastAccessDate</th>\n",
       "      <th>Views</th>\n",
       "      <th>UpVotes</th>\n",
       "      <th>DownVotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.7276</td>\n",
       "      <td>10.1861</td>\n",
       "      <td>12.3571</td>\n",
       "      <td>173</td>\n",
       "      <td>14</td>\n",
       "      <td>[Teacher, Student, Editor, Cleanup, Organizer,...</td>\n",
       "      <td>Riker</td>\n",
       "      <td>2420</td>\n",
       "      <td>2017-01-31 19:07:26.043</td>\n",
       "      <td>2022-08-28 21:23:28.733</td>\n",
       "      <td>131</td>\n",
       "      <td>104</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>0.1889</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>4.3333</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>[Teacher, Editor, Supporter, Yearling, Nice An...</td>\n",
       "      <td>mic</td>\n",
       "      <td>248</td>\n",
       "      <td>2017-01-31 19:09:02.657</td>\n",
       "      <td>2020-02-25 19:15:25.487</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[Teacher, Student, Supporter, Autobiographer]</td>\n",
       "      <td>RocketRuwan</td>\n",
       "      <td>99</td>\n",
       "      <td>2017-01-31 19:09:30.553</td>\n",
       "      <td>2021-09-17 17:19:34.800</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.3193</td>\n",
       "      <td>0.9578</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>[Teacher, Student, Supporter, Critic, Yearling...</td>\n",
       "      <td>Joe</td>\n",
       "      <td>418</td>\n",
       "      <td>2017-01-31 19:09:55.527</td>\n",
       "      <td>2021-11-28 21:08:45.967</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>0.5686</td>\n",
       "      <td>2.8428</td>\n",
       "      <td>13.4000</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>[Teacher, Student, Editor, Organizer, Supporte...</td>\n",
       "      <td>gerrit</td>\n",
       "      <td>1589</td>\n",
       "      <td>2017-01-31 19:09:58.223</td>\n",
       "      <td>2024-01-18 11:04:41.247</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AvgNormalizedScore  TotalNormalizedScore  AvgRawScore  \\\n",
       "OwnerUserId                                                          \n",
       "6.0                      0.7276               10.1861      12.3571   \n",
       "16.0                     0.1889                0.5667       4.3333   \n",
       "18.0                     0.4667                0.4667       7.0000   \n",
       "20.0                     0.3193                0.9578       8.0000   \n",
       "21.0                     0.5686                2.8428      13.4000   \n",
       "\n",
       "             TotalRawScore  TotalAnswers  \\\n",
       "OwnerUserId                                \n",
       "6.0                    173            14   \n",
       "16.0                    13             3   \n",
       "18.0                     7             1   \n",
       "20.0                    24             3   \n",
       "21.0                    67             5   \n",
       "\n",
       "                                                        badges  DisplayName  \\\n",
       "OwnerUserId                                                                   \n",
       "6.0          [Teacher, Student, Editor, Cleanup, Organizer,...        Riker   \n",
       "16.0         [Teacher, Editor, Supporter, Yearling, Nice An...          mic   \n",
       "18.0             [Teacher, Student, Supporter, Autobiographer]  RocketRuwan   \n",
       "20.0         [Teacher, Student, Supporter, Critic, Yearling...          Joe   \n",
       "21.0         [Teacher, Student, Editor, Organizer, Supporte...       gerrit   \n",
       "\n",
       "             Reputation            CreationDate          LastAccessDate  \\\n",
       "OwnerUserId                                                               \n",
       "6.0                2420 2017-01-31 19:07:26.043 2022-08-28 21:23:28.733   \n",
       "16.0                248 2017-01-31 19:09:02.657 2020-02-25 19:15:25.487   \n",
       "18.0                 99 2017-01-31 19:09:30.553 2021-09-17 17:19:34.800   \n",
       "20.0                418 2017-01-31 19:09:55.527 2021-11-28 21:08:45.967   \n",
       "21.0               1589 2017-01-31 19:09:58.223 2024-01-18 11:04:41.247   \n",
       "\n",
       "             Views  UpVotes  DownVotes  \n",
       "OwnerUserId                             \n",
       "6.0            131      104         17  \n",
       "16.0             2       20          0  \n",
       "18.0             3        4          0  \n",
       "20.0             8       15          1  \n",
       "21.0            12      114          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create master user-level DataFrame by merging computed metrics, badges and user profile data\n",
    "# Merge user_metrics (which has OwnerUserId) with normalized_score and answer_volume\n",
    "master_df = user_metrics.merge(normalized_score, on='OwnerUserId', how='left')\n",
    "master_df = master_df.merge(answer_volume, on='OwnerUserId', how='left')\n",
    "\n",
    "# Merge bages to master dataframe\n",
    "master_df = master_df.merge(badges_by_user, left_on='OwnerUserId', right_on=\"UserId\", how='left')\n",
    "\n",
    "# Merge basic user profile information from users (Id -> OwnerUserId)\n",
    "users_profile = users.copy()\n",
    "\n",
    "# Choose a subset of useful columns to bring in to avoid huge DataFrame\n",
    "profile_cols = [c for c in ['Id','DisplayName','Reputation','CreationDate','LastAccessDate','Views','UpVotes','DownVotes']]\n",
    "users_profile = users_profile[profile_cols]\n",
    "master_df = master_df.merge(users_profile, left_on='OwnerUserId', right_on=\"Id\", how='left')\n",
    "\n",
    "# Set OwnerUserId as index and sort by TotalNormalizedScore desc\n",
    "master_df = master_df.set_index('OwnerUserId')\n",
    "master_df.drop(columns=[\"UserId\", \"Id\", \"NormalizedScore\", \"AnswerCount_norm\", \"TotalAnswerVolume\"], inplace=True) #removing duplicate columns\n",
    "\n",
    "# Show summary\n",
    "print('Master dataframe shape:', master_df.shape)\n",
    "print('Master df info:')\n",
    "print(master_df.info())\n",
    "print('Master df head:')\n",
    "display(master_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da1ea8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv('data/master_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsstds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
